{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorboard.backend.event_processing import event_accumulator\n",
    "\n",
    "import scvi.dataset\n",
    "import scvi.models\n",
    "import scvi.inference\n",
    "import scvi.inference.annotation\n",
    "import Cell_BLAST as cb\n",
    "\n",
    "import exputils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb.config.RANDOM_SEED = 0\n",
    "plt.rcParams['svg.fonttype'] = \"none\"\n",
    "plt.rcParams['font.family'] = \"Arial\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = exputils.pick_gpu_lowest_memory()\n",
    "PATH = \"./training_dynamics/\"\n",
    "os.makedirs(PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell BLAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = cb.data.ExprDataSet.read_dataset(\"../../Datasets/data/Baron_human/data.h5\")\n",
    "ds[:, ds.uns[\"seurat_genes\"]].to_anndata().write_h5ad(os.path.join(PATH, \"ds.h5ad\"))\n",
    "ds_scvi = scvi.dataset.AnnDataset(\"ds.h5ad\", save_path=PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(PATH, \"cb\")):\n",
    "    shutil.rmtree(os.path.join(PATH, \"cb\"))\n",
    "model = cb.directi.fit_DIRECTi(\n",
    "    ds, ds.uns[\"seurat_genes\"], batch_effect=\"donor\",\n",
    "    latent_dim=10, cat_dim=20,\n",
    "    random_seed=0, path=os.path.join(PATH, \"cb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ea = event_accumulator.EventAccumulator(\n",
    "    glob.glob(os.path.join(PATH, \"cb\", \"summary\", \"*.tfevents.*\"))[0],\n",
    "    size_guidance={event_accumulator.SCALARS: 0}\n",
    ").Reload()\n",
    "ea.Tags()[\"scalars\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_loss_df = pd.concat([\n",
    "    pd.DataFrame.from_records([\n",
    "        {\"Epoch\": item.step, \"Model\": \"Cell BLAST\", \"Partition\": \"Training\", \"Negative log-likelihood\": item.value}\n",
    "        for item in ea.Scalars(\"decoder/NB/raw_loss:0 (train)\")\n",
    "    ]),\n",
    "    pd.DataFrame.from_records([\n",
    "        {\"Epoch\": item.step, \"Model\": \"Cell BLAST\", \"Partition\": \"Validation\", \"Negative log-likelihood\": item.value}\n",
    "        for item in ea.Scalars(\"decoder/NB/raw_loss:0 (val)\")\n",
    "    ])\n",
    "]).loc[:, [\"Epoch\", \"Model\", \"Partition\", \"Negative log-likelihood\"]]\n",
    "cb_loss_df[\"Negative log-likelihood\"] *= len(ds.uns[\"seurat_genes\"])\n",
    "cb_loss_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_indices = cb.utils.encode_integer(ds.obs[\"donor\"])[0]\n",
    "ds_scvi.batch_indices, ds_scvi.n_batches = batch_indices.reshape((-1, 1)), np.unique(batch_indices).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "scvi_model = scvi.models.VAE(ds_scvi.nb_genes, n_latent=10, n_batch=ds_scvi.n_batches)\n",
    "scvi_trainer = scvi.inference.UnsupervisedTrainer(\n",
    "    scvi_model, ds_scvi, use_cuda=True, metrics_to_monitor=[\"ll\"], frequency=1,\n",
    "    early_stopping_kwargs=dict(\n",
    "        early_stopping_metric=\"ll\", save_best_state_metric=\"ll\",\n",
    "        patience=30, threshold=0\n",
    "    )\n",
    ")\n",
    "scvi_trainer.train(n_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scvi_loss_df = pd.DataFrame(scvi_trainer.history).reset_index().rename(columns={\n",
    "    \"index\": \"Epoch\",\n",
    "    \"ll_train_set\": \"Training\",\n",
    "    \"ll_test_set\": \"Validation\"\n",
    "}).melt(\n",
    "    id_vars=\"Epoch\", var_name=\"Partition\", value_name=\"Negative log-likelihood\"\n",
    ").assign(Model=\"scVI\").loc[:, [\"Epoch\", \"Model\", \"Partition\", \"Negative log-likelihood\"]]\n",
    "scvi_loss_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_df = pd.concat([cb_loss_df, scvi_loss_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../Evaluation/palette_method.json\", \"r\") as f:\n",
    "    palette = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.5, 3.5))\n",
    "ax = sns.lineplot(\n",
    "    x=\"Epoch\", y=\"Negative log-likelihood\",\n",
    "    hue=\"Model\", style=\"Partition\",\n",
    "    palette=palette, data=loss_df, ax=ax\n",
    ")\n",
    "ax.set_ylim(300, 1000)\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.legend(\n",
    "    bbox_to_anchor=(1.05, 0.5), loc=\"center left\",\n",
    "    borderaxespad=0.0, frameon=False\n",
    ")\n",
    "fig.savefig(os.path.join(PATH, \"ll_cmp.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Cell BLAST discriminator losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_d_loss_df = pd.concat([\n",
    "    pd.DataFrame.from_records([\n",
    "        {\"Epoch\": item.step, \"Loss\": r\"$D_c\\ loss$\", \"Partition\": \"Training\", \"Value\": item.value}\n",
    "        for item in ea.Scalars(\"discriminator/CatGau/cat/d_loss/d_loss:0 (train)\")\n",
    "    ]),\n",
    "    pd.DataFrame.from_records([\n",
    "        {\"Epoch\": item.step, \"Loss\": r\"$D_c\\ loss$\", \"Partition\": \"Validation\", \"Value\": item.value}\n",
    "        for item in ea.Scalars(\"discriminator/CatGau/cat/d_loss/d_loss:0 (val)\")\n",
    "    ])\n",
    "]).loc[:, [\"Epoch\", \"Loss\", \"Partition\", \"Value\"]]\n",
    "cat_d_loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gau_d_loss_df = pd.concat([\n",
    "    pd.DataFrame.from_records([\n",
    "        {\"Epoch\": item.step, \"Loss\": r\"$D_z\\ loss$\", \"Partition\": \"Training\", \"Value\": item.value}\n",
    "        for item in ea.Scalars(\"discriminator/CatGau/gau/d_loss/d_loss:0 (train)\")\n",
    "    ]),\n",
    "    pd.DataFrame.from_records([\n",
    "        {\"Epoch\": item.step, \"Loss\": r\"$D_z\\ loss$\", \"Partition\": \"Validation\", \"Value\": item.value}\n",
    "        for item in ea.Scalars(\"discriminator/CatGau/gau/d_loss/d_loss:0 (val)\")\n",
    "    ])\n",
    "]).loc[:, [\"Epoch\", \"Loss\", \"Partition\", \"Value\"]]\n",
    "gau_d_loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_d_loss_df = pd.concat([\n",
    "    pd.DataFrame.from_records([\n",
    "        {\"Epoch\": item.step, \"Loss\": r\"$D_b\\ loss$\", \"Partition\": \"Training\", \"Value\": item.value}\n",
    "        for item in ea.Scalars(\"discriminator/donor/d_loss:0 (train)\")\n",
    "    ]),\n",
    "    pd.DataFrame.from_records([\n",
    "        {\"Epoch\": item.step, \"Loss\": r\"$D_b\\ loss$\", \"Partition\": \"Validation\", \"Value\": item.value}\n",
    "        for item in ea.Scalars(\"discriminator/donor/d_loss:0 (val)\")\n",
    "    ])\n",
    "])\n",
    "batch_d_loss_df = batch_d_loss_df.loc[\n",
    "    batch_d_loss_df[\"Value\"] != 0,\n",
    "    [\"Epoch\", \"Loss\", \"Partition\", \"Value\"]\n",
    "]\n",
    "batch_d_loss_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(4.5, 3.5))\n",
    "ax = sns.lineplot(\n",
    "    x=\"Epoch\", y=\"Value\", hue=\"Loss\", style=\"Partition\",\n",
    "    data=pd.concat([gau_d_loss_df, cat_d_loss_df, batch_d_loss_df]), ax=ax\n",
    ")\n",
    "ax.spines[\"right\"].set_visible(False)\n",
    "ax.spines[\"top\"].set_visible(False)\n",
    "ax.legend(\n",
    "    bbox_to_anchor=(1.05, 0.5), loc=\"center left\",\n",
    "    borderaxespad=0.0, frameon=False\n",
    ")\n",
    "fig.savefig(os.path.join(PATH, \"cb_d_loss.pdf\"), bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
